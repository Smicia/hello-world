<!--
Creative Commons Attribution-NonCommercial-NoDerivatives
https://creativecommons.org/licenses/by-nc-nd/4.0/
-->
<h1>The Markup’s Work Cited in Effort to Outlaw Discriminatory Algorithms</h1>

<h2>Investigation on tenant screening used to illustrate needed reforms</h2>

<p>By: Malena Carollo </p>

<p><a href="https://themarkup.org/locked-out/2021/12/17/the-markups-work-cited-in-effort-to-outlaw-discriminatory-algorithms"><img src="https://themarkup.org/static/img/republish-logo.png?the-markups-work-cited-in-effort-to-outlaw-discriminatory-algorithms" alt="Originally published on themarkup.org" /></a></p>

<p>A bill introduced in Washington, D.C., last week takes aim at a wide swath of discriminatory algorithms, and the <a href="https://oag.dc.gov/release/ag-racine-introduces-legislation-stop">author cited</a> The Markup’s <a href="https://themarkup.org/series/locked-out">Locked Out</a> series to explain why reforms are needed. </p>

<p>The proposal seeks to hold companies and organizations that do business in the nation’s capital responsible for algorithms they use to make decisions on housing, education, employment, and “public accommodations and services” such as insurance, health care, and credit. If passed by the Council of the District of Columbia, violations would carry a fine of up to $10,000 each.</p>

<p>“This so-called artificial intelligence is the engine of algorithms that are, in fact, far less smart than they are portrayed and more discriminatory and unfair than big data wants you to know,” Karl Racine, D.C.’s attorney general, said in a news release. “Our legislation would end the myth of the intrinsic egalitarian nature of [artificial intelligence].”</p>

<p>Last year, <a href="https://themarkup.org/locked-out/2020/05/28/access-denied-faulty-automated-background-checks-freeze-out-renters">The Markup and The New York Times found</a> that tenant background checks are widely used and often rife with inaccuracies, which can bar qualified people from obtaining housing.&nbsp;</p>

<p>People with common names are particularly at risk for having incorrect reports, such as Latinos <a href="https://www.census.gov/library/stories/2017/08/what-is-in-a-name.html">who often share a smaller pool of unique last names.</a> Common names, as well as hyphenated last names, can trigger a false match if the screening company relies solely on an algorithmic match and doesn’t use other information to corroborate someone’s identity.</p>

<p>Tenant screening companies at the time said renters rarely dispute reports, and the Consumer Data Industry Association, a trade group that represents background check and consumer reporting companies, said that systemic issues don’t exist. The group declined to comment on the bill.&nbsp;</p>

<p>Last month, the Consumer Financial Protection Bureau <a href="https://themarkup.org/locked-out/2021/11/09/federal-agency-recommends-changes-in-tenant-screening-citing-investigation-by-the-markup">issued an advisory against such “name only” matching</a> to curb errors. Similarly, the chair of the Senate Committee on Banking, Housing, and Urban Affairs <a href="https://themarkup.org/locked-out/2021/10/26/senator-calls-for-review-of-powerful-tenant-screening-industry">sent a letter to the head of the CFPB in October</a> calling for a review of the tenant screening industry; The Markup and New York Times’ work was cited in it.</p>

<p>The Washington, D.C., bill, which was introduced by D.C. Council chair Phil Mendelson on Racine’s behalf, is aimed at companies whose businesses focus on data and make decisions with algorithms.</p>

<p>If it’s approved, companies would be required to audit their algorithms annually for potential discrimination and submit a report to Racine’s office, which will also handle enforcement.&nbsp;</p>

<p>“You can’t just plead ignorance,” said Laura Moy, director of Georgetown Law’s Communications and Technology Law Clinic, which helped research and draft the bill. “You have to go out and proactively find out whether or not there is discrimination and then you have to tell us what you’re doing to address it.”</p>

<p>Companies would also be required to inform consumers about how they use people’s personal information to make decisions with algorithms and where they got that information. D.C. residents would also be able to challenge inaccuracies, and the updated information would be used to re-generate the report or algorithmic decision.&nbsp;</p>
<p>This article was <a href="https://themarkup.org/locked-out/2021/12/17/the-markups-work-cited-in-effort-to-outlaw-discriminatory-algorithms">originally published on The Markup</a> and was republished under the <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives<a> license.</p>
